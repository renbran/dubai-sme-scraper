#!/usr/bin/env python3
# ================================================================
# ğŸš€ REAL-TIME SCRAPER PROGRESS TRACKER
# ================================================================

import os
import csv
import json
import time
from datetime import datetime, timedelta

def get_latest_results():
    """Get the latest CSV results file"""
    results_dir = "d:/apify/apify_actor/results"
    csv_files = [f for f in os.listdir(results_dir) if f.endswith('.csv') and 'fresh-dubai-businesses' in f]
    if csv_files:
        latest_file = max(csv_files, key=lambda x: os.path.getctime(os.path.join(results_dir, x)))
        return os.path.join(results_dir, latest_file)
    return None

def display_live_progress():
    """Display live progress of the scraper"""
    
    print("=" * 80)
    print("ğŸš€ DUBAI SME SCRAPER - LIVE PROGRESS TRACKER")
    print("=" * 80)
    
    # Session info
    current_time = datetime.now()
    session_start = datetime(2025, 10, 15, 9, 11, 0)  # Latest session start time
    elapsed = current_time - session_start
    remaining = timedelta(hours=1) - elapsed
    
    print(f"ğŸ“… Current Time: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"â±ï¸  Session Started: {session_start.strftime('%H:%M:%S')}")
    print(f"â³ Elapsed Time: {str(elapsed).split('.')[0]}")
    print(f"â° Time Remaining: {str(remaining).split('.')[0] if remaining.total_seconds() > 0 else 'Session Complete'}")
    
    # Progress bar
    progress_percent = min(100, (elapsed.total_seconds() / 3600) * 100)
    progress_bar = "â–ˆ" * int(progress_percent // 5) + "â–‘" * (20 - int(progress_percent // 5))
    print(f"ğŸ“Š Progress: [{progress_bar}] {progress_percent:.1f}%")
    
    print("\n" + "â”€" * 80)
    print("ğŸ“ˆ CURRENT RESULTS")
    print("â”€" * 80)
    
    # Check latest results
    latest_file = get_latest_results()
    if latest_file and os.path.exists(latest_file):
        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                leads = list(reader)
                
                print(f"ğŸ“„ Latest Results File: {os.path.basename(latest_file)}")
                print(f"ğŸ“Š Total Leads Collected: {len(leads)}")
                
                if leads:
                    # Analyze lead quality
                    urgent_leads = [l for l in leads if l.get('Priority') == 'URGENT']
                    high_leads = [l for l in leads if l.get('Priority') == 'HIGH']
                    email_leads = [l for l in leads if l.get('Email') and l['Email'] not in ['Not available', '']]
                    website_leads = [l for l in leads if l.get('Website') and l['Website'] not in ['Not available', '']]
                    
                    print(f"ğŸ”¥ URGENT Priority: {len(urgent_leads)} leads")
                    print(f"â­ HIGH Priority: {len(high_leads)} leads")
                    print(f"ğŸ“§ With Email: {len(email_leads)} leads")
                    print(f"ğŸŒ With Website: {len(website_leads)} leads")
                    
                    # Calculate average quality score
                    quality_scores = [float(l.get('Quality Score', 0)) for l in leads if l.get('Quality Score', '').replace('.', '').isdigit()]
                    avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
                    print(f"ğŸ¯ Average Quality Score: {avg_quality:.1f}/10")
                    
                    print("\n" + "â”€" * 80)
                    print("ğŸ† TOP QUALITY LEADS")
                    print("â”€" * 80)
                    
                    # Show top 3 leads
                    sorted_leads = sorted(leads, key=lambda x: float(x.get('Quality Score', 0)), reverse=True)[:3]
                    
                    for i, lead in enumerate(sorted_leads, 1):
                        print(f"\nğŸ¢ #{i}. {lead.get('Name', 'Unknown Company')}")
                        print(f"   ğŸ“± Phone: {lead.get('Phone', 'N/A')}")
                        print(f"   ğŸ“§ Email: {lead.get('Email', 'N/A')}")
                        print(f"   ğŸŒ Website: {lead.get('Website', 'N/A')}")
                        print(f"   ğŸ“ Address: {lead.get('Address', 'N/A')[:50]}...")
                        print(f"   â­ Priority: {lead.get('Priority', 'N/A')}")
                        print(f"   ğŸ¯ Quality Score: {lead.get('Quality Score', 'N/A')}/10")
                        print(f"   ğŸ·ï¸  Category: {lead.get('Category', 'N/A')}")
        
        except Exception as e:
            print(f"âŒ Error reading results: {e}")
    else:
        print("â³ No results file found yet - scraper is still initializing...")
    
    # Webhook status
    print("\n" + "â”€" * 80)
    print("ğŸ”— WEBHOOK STATUS")
    print("â”€" * 80)
    print("ğŸŒ Webhook URL: https://scholarixglobal.com/web/hook/22c7e29b-1d45-4ec8-93cc-fe62708bddc7")
    print("ğŸ“¦ Module: webhook_crm")
    print("âš ï¸  Status: Needs field mapping configuration (500 errors)")
    print("ğŸ’¾ Backup: All leads saved to CSV âœ…")
    
    # Next steps
    print("\n" + "â”€" * 80)
    print("ğŸ“‹ NEXT STEPS")
    print("â”€" * 80)
    print("1. ğŸ”§ Configure webhook_crm field mapping in Odoo")
    print("2. ğŸ§ª Test webhook with sample lead")
    print("3. âœ… Enable real-time CRM integration")
    print("4. ğŸ“Š Monitor lead quality and CRM pipeline")
    
    # Expected completion
    completion_time = session_start + timedelta(hours=1)
    print(f"\nğŸ• Expected Completion: {completion_time.strftime('%H:%M:%S')}")
    print("ğŸ“Š Expected Total Leads: 50-100 high-quality companies")
    print("ğŸ¯ Focus: ERP/Automation ready Dubai SMEs")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    display_live_progress()